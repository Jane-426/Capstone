{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T07:17:50.677231Z",
     "start_time": "2023-12-11T07:17:50.038190Z"
    }
   },
   "id": "9cc2c48c03b94470"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def add(path):\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "add(\"/Users/yuchenji/PycharmProjects/auction-gym/src\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T07:17:51.438100Z",
     "start_time": "2023-12-11T07:17:51.426009Z"
    }
   },
   "id": "d957ce35"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/yuchenji/PycharmProjects/auction-gym/src')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T07:17:54.116649Z",
     "start_time": "2023-12-11T07:17:52.282923Z"
    }
   },
   "id": "e68e19aa8239b818"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from auction_gym.src import main\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T07:17:54.945096Z",
     "start_time": "2023-12-11T07:17:54.938384Z"
    }
   },
   "id": "27158bad55c0bff"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/yuchenji/PycharmProjects/auction-gym/src')\n",
    "from main import parse_config, instantiate_agents, instantiate_auction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T07:17:56.105764Z",
     "start_time": "2023-12-11T07:17:56.094470Z"
    }
   },
   "id": "c12b191c87648853"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "import main"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T02:44:36.544021Z",
     "start_time": "2023-12-11T02:44:36.537371Z"
    }
   },
   "id": "dd671dcf24078e8d"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004233926115349491\n"
     ]
    }
   ],
   "source": [
    "from main import parse_config, instantiate_agents, instantiate_auction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-11T06:58:21.887991Z",
     "start_time": "2023-12-11T06:57:24.407573Z"
    }
   },
   "id": "e8f198aacd2a58c"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c8c140e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T03:50:18.614916Z",
     "start_time": "2023-12-11T03:49:22.685100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.004233926115349491\n"
     ]
    }
   ],
   "source": [
    "from ad_auction import AdAuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0300f9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T23:42:14.771210Z",
     "start_time": "2023-12-10T23:42:14.706952Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Bidder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbo_bidder\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PolicyLearningBidder\n",
      "File \u001B[0;32m~/PycharmProjects/Capstone/bo_bidder.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mPolicyLearningBidder\u001B[39;00m(\u001B[43mBidder\u001B[49m):\n\u001B[1;32m      2\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\" A bidder that estimates the optimal bid shading distribution via policy learning \"\"\"\u001B[39;00m\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, rng, gamma_sigma, loss, init_gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.0\u001B[39m):\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Bidder' is not defined"
     ]
    }
   ],
   "source": [
    "def evaluate(ad_auction, num_iterations):\n",
    "    trace = []\n",
    "    for _ in range(num_iterations):\n",
    "        r = ad_auction.run_episode()\n",
    "        trace.append(r)\n",
    "    return np.array(trace).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9db36d",
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-11T07:24:54.616834Z"
    }
   },
   "source": [
    "# Advantage-E\n",
    "\n",
    "Bidders get an advantage when they shade their bids, i.e. when they bid a little lower than the ad is really worth, because they save money if they win the auction. If they bid *too* low, however, they lose the auction, which is bad because they want the ad slot.\n",
    "\n",
    "With `config-advantage-E.json` our agent shades it bid w/`EmpiricalShadedBidder` and the other agents bid the true cost (`TruthfulBidder`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "044058d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T03:56:46.273615Z",
     "start_time": "2023-12-11T03:53:55.262585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TO -0.000545250209260078\n",
      "EO -0.011657106026253928\n",
      "VO -0.0035311654468497353\n",
      "EO -0.011657106026253928\n"
     ]
    }
   ],
   "source": [
    "ad_auction = AdAuction(\"configs/config-advantage-BO.json\", warm_up_iterations=1000)\n",
    "print(evaluate(ad_auction, num_iterations=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65d49e7",
   "metadata": {},
   "source": [
    "The number printed above is our average reward for an episode.\n",
    "\n",
    "[Actually, it's called \"return\" when talking about an episode. One step -- in this case, an auction -- yields a reward. When you take many steps in sequence, receiving a reward for each step, you can sum (or average) of the rewards and call it \"return\".]\n",
    "\n",
    "In any case, the *return*, here, is `[our net utility - mean(other agent's net utility)] / (mean gross utility)` averaged over the `num_iterations` simulated auctions. The mean gross utility is a mean over all of the agents (including us). It's a measure of the total value generated by the auction -- the total revenue that's up for grabs. That value (i.e., revenue) is split between the bidders and the company that runs the auction.\n",
    "\n",
    "Since the number returned by `evaluate()` is compared to the other agents in the auctions, we'llrefer to it as our *advantage*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1545754",
   "metadata": {},
   "source": [
    "# TO/EO/VO\n",
    "\n",
    "Now it gets interesting. We bid truthfully (`TruthfulBidder`), and the other agents bid either:\n",
    "\n",
    "- TO: Truthfully, also\n",
    "- EO: Shading with `EmpiricalShadedBidder`\n",
    "- VO: Shading with `ValueLearningBidder`\n",
    "\n",
    "In the first case, TO, we receive exactly zero advantage. The actual number shown below for TO is non-zero b/c the auction process is noisy. That's why we need to run multiple times -- and that's why real auction experiments take so long to run. (And, guess what, Bayesian optimization was made for problems where evaluation takes a long time and is noisy.)\n",
    "\n",
    "In the other two cases, EO and VO, we have negative advantage. It's better to shade your bid in a smart way than to bid full price all the time.\n",
    "\n",
    "## Warm-up\n",
    "\n",
    "Notice the argument `warm_up_iterations`. The tells `AdAuction` how many times to run the auction before doing any evaluation at all. During the warm-up time the learning agents (EO and VO) get a chance to learn about the dynamics of the auction. The auction simulator is interesting in that the agents are aware of each others' behavior via the auction, so they are all learning simultaneously, making bids, and learning even more from observing others' bids. If you look at the plots at the bottom of `auction-gym/src\n",
    "/Getting Started with AuctionGym (2. Effects of Bid Shading).ipynb` you'll see that it can take a few iterations --each of which consists of many auction rounds -- before the plots settle down. Called a transient, it's there because the agents take time to learn.\n",
    "\n",
    "We want to do our evaluations after the transient. That will simulate an engineer creating a new ad-bidding bot and trying to optimize it via experiment in an already-functioning ad auction market. Also, it's after the transient that the other agents are at their best.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69fb4620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T01:40:50.233097Z",
     "start_time": "2023-12-08T01:40:50.197185Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdAuction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ttype \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTO\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEO\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVO\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m----> 2\u001B[0m     ad_auction \u001B[38;5;241m=\u001B[39m \u001B[43mAdAuction\u001B[49m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconfigs/config-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mttype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.json\u001B[39m\u001B[38;5;124m\"\u001B[39m,  warm_up_iterations\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m (ttype, evaluate(ad_auction, num_iterations\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10000\u001B[39m))\n",
      "\u001B[0;31mNameError\u001B[0m: name 'AdAuction' is not defined"
     ]
    }
   ],
   "source": [
    "for ttype in [\"TO\", \"EO\", \"VO\"]:\n",
    "    ad_auction = AdAuction(f\"configs/config-{ttype}.json\",  warm_up_iterations=1000)\n",
    "    print (ttype, evaluate(ad_auction, num_iterations=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf27c8",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "The goal is to optimize a bidder with Bayesian optimization. To do that we need:\n",
    "\n",
    "1. A way to simulate a sequence of experiments. Done. See above.\n",
    "2. A parameterized agent.\n",
    "3. A Bayesian optimizer.\n",
    "\n",
    "\n",
    "This week, work on step 2.\n",
    "\n",
    "## BOBidder\n",
    "\n",
    "We want to optimize parameters by observing rewards (or, in our case, \"advantages\"). When you optimize this way in RL, it's called *policy search*. If you look in the auction-gym codebase you'll find `PolicyLearningBidder`. Taht will be our starting point for BOBidder.\n",
    "\n",
    "To get started, set up an evaluation of a hacked copy of `PolicyLearningBidder`:\n",
    "\n",
    "- Make a copy of `PolicyLearningBidder` a new file (`bo_bidder.py`) in your Capstone directy.\n",
    "- Completely remove the method `update()` -- even the signature. You can also remove the code that is referred to as \"Option 1\". We're only going to use \"Option 2\". Also, get rid of any references to `gamma` or any other variables that you're not using. `self.model` will be doing the bulk of the work.\n",
    "- Copy `configs/config-advantage-E.json` to `configs/config-advantage-BO.json`. Inside, replace the `EmpiricalShadedBidder` with `BOBidder`.\n",
    "- Try to get `evaluate()` to run on your new config file.\n",
    "\n",
    "It probably won't perform well, but that's because it's not optimized. The first step is just getting it to run.\n",
    "\n",
    "Next, you'll need to figure our how to get and set the parameters. Create two methods in `BOBidder`:\n",
    "- `get_parameters(self) -> np.ndarray`, and\n",
    "- `set_parameters(self, parameters: np.ndarray)`\n",
    "\n",
    "and make them do the right things.  Fortunately, I have some code lying around that could help. See `ParametersDirect` in `parameters_direct.py`. It should help you get and set the parameters of `self.model`, which is a PyTorch module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aceaf98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea239ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf499c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
